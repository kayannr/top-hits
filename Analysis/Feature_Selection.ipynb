{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9bd687",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Feature selection](#feature)\n",
    "    * [Variance threshold](#var)\n",
    "    * [Filter-based methods](#filterbased)\n",
    "        * [Pearson correlation](#pearson)\n",
    "        * [Chi-square Test ](#chi)\n",
    "    * [Information criterions](#infocri)\n",
    "        * [AIC](#aic)\n",
    "        * [BIC](#bic)\n",
    "    * [Wrapper-based methods](#wrapper)\n",
    "        * [Recursive feature elimination](#recursive)\n",
    "        * [Forward feature selection](#forward)\n",
    "        * [Backward Elimination](#backward)\n",
    "    * [Embedded methods](#embedded)\n",
    "        * [Ridge Regression](#ridge)\n",
    "        * [Tree-based](#tree)\n",
    "        * [Lasso](#lasso)\n",
    "    * [Combined results](#comb)\n",
    "* [Regression analysis](#reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce87eac1",
   "metadata": {},
   "source": [
    "# Feature Selection <a class=\"anchor\" id=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6fac13",
   "metadata": {},
   "source": [
    "Different feature selection methods can be used to determine whether audio and lyrics features can be used to predict popularity measured by number of streams and specifically identify the best features to use for predicting popularity of songs. If any of the features are useful for predicting popularity, then a predictive model can be created by utilizing those features. It is often useful to perform feature selection and reduce the number of features used in a model to avoid overfitting (perfect training data fit but won't generalize to new samples), simplify the model, and exclude non-informative features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1849a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d300094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_names</th>\n",
       "      <th>track_name</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>streams</th>\n",
       "      <th>country</th>\n",
       "      <th>danceability</th>\n",
       "      <th>...</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_trans</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_alpha3</th>\n",
       "      <th>len_words_orig</th>\n",
       "      <th>len_words_trans</th>\n",
       "      <th>lyrics_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0yLdNVWF3Srea0uzk55zFn</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>Flowers</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124198</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.707</td>\n",
       "      <td>...</td>\n",
       "      <td>200455.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>We were good, we were gold\\nKinda dream that c...</td>\n",
       "      <td>we were good we were gold kinda dream that can...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>ARE</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>good gold dream sell right til build home watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1Qrg8KqiBpW07V7PNxwwwL</td>\n",
       "      <td>SZA</td>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>Top Dawg Entertainment/RCA Records</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>106927</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>153947.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>I'm still a fan even though I was salty\\nHate ...</td>\n",
       "      <td>im still a fan even though i was salty hate to...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>ARE</td>\n",
       "      <td>362</td>\n",
       "      <td>362</td>\n",
       "      <td>fan even though salty hate see broad know happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6AQbmUe0Qwf5PZnt4HmTXv</td>\n",
       "      <td>PinkPantheress, Ice Spice</td>\n",
       "      <td>Boy's a liar Pt. 2</td>\n",
       "      <td>Warner Records</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>83627</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.696</td>\n",
       "      <td>...</td>\n",
       "      <td>131013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>Take a look inside your heart\\nIs there any ro...</td>\n",
       "      <td>take a look inside your heart is there any roo...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>ARE</td>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>take look inside heart room room would hold br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0WtM2NBVQNNJLh6scP13H8</td>\n",
       "      <td>Rema, Selena Gomez</td>\n",
       "      <td>Calm Down (with Selena Gomez)</td>\n",
       "      <td>Mavin Records / Jonzing World</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>79714</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.801</td>\n",
       "      <td>...</td>\n",
       "      <td>239318.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>Vibez\\nOh, no\\nAnother banger\\nBaby, calm down...</td>\n",
       "      <td>vibez oh no another banger baby calm down calm...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>ARE</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>another banger baby calm calm girl body put he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2dHHgzDwk4BJdRwy9uXhTO</td>\n",
       "      <td>Metro Boomin, The Weeknd, 21 Savage</td>\n",
       "      <td>Creepin' (with The Weeknd &amp; 21 Savage)</td>\n",
       "      <td>Republic Records</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>79488</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.715</td>\n",
       "      <td>...</td>\n",
       "      <td>221520.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>Ooh, ooh-ooh\\nOoh-ooh-ooh, ooh, ooh-ooh (Just ...</td>\n",
       "      <td>ooh oohooh oohoohooh ooh oohooh just cant beli...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>ARE</td>\n",
       "      <td>458</td>\n",
       "      <td>456</td>\n",
       "      <td>believe man want somebody say saw person kiss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                         artist_names  \\\n",
       "0           0  0yLdNVWF3Srea0uzk55zFn                          Miley Cyrus   \n",
       "1           1  1Qrg8KqiBpW07V7PNxwwwL                                  SZA   \n",
       "2           2  6AQbmUe0Qwf5PZnt4HmTXv            PinkPantheress, Ice Spice   \n",
       "3           3  0WtM2NBVQNNJLh6scP13H8                   Rema, Selena Gomez   \n",
       "4           4  2dHHgzDwk4BJdRwy9uXhTO  Metro Boomin, The Weeknd, 21 Savage   \n",
       "\n",
       "                               track_name                              source  \\\n",
       "0                                 Flowers                            Columbia   \n",
       "1                               Kill Bill  Top Dawg Entertainment/RCA Records   \n",
       "2                      Boy's a liar Pt. 2                      Warner Records   \n",
       "3           Calm Down (with Selena Gomez)       Mavin Records / Jonzing World   \n",
       "4  Creepin' (with The Weeknd & 21 Savage)                    Republic Records   \n",
       "\n",
       "   rank  weeks_on_chart  streams               country  danceability  ...  \\\n",
       "0     1               5   124198  United Arab Emirates         0.707  ...   \n",
       "1     2              10   106927  United Arab Emirates         0.644  ...   \n",
       "2     3               2    83627  United Arab Emirates         0.696  ...   \n",
       "3     4              25    79714  United Arab Emirates         0.801  ...   \n",
       "4     5              11    79488  United Arab Emirates         0.715  ...   \n",
       "\n",
       "   duration_ms  time_signature  album_release_date  \\\n",
       "0     200455.0             4.0          2023-01-13   \n",
       "1     153947.0             4.0          2022-12-08   \n",
       "2     131013.0             4.0          2023-02-03   \n",
       "3     239318.0             4.0          2022-08-25   \n",
       "4     221520.0             4.0          2022-12-02   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  We were good, we were gold\\nKinda dream that c...   \n",
       "1  I'm still a fan even though I was salty\\nHate ...   \n",
       "2  Take a look inside your heart\\nIs there any ro...   \n",
       "3  Vibez\\nOh, no\\nAnother banger\\nBaby, calm down...   \n",
       "4  Ooh, ooh-ooh\\nOoh-ooh-ooh, ooh, ooh-ooh (Just ...   \n",
       "\n",
       "                                        lyrics_trans  continent  iso_alpha3  \\\n",
       "0  we were good we were gold kinda dream that can...       Asia         ARE   \n",
       "1  im still a fan even though i was salty hate to...       Asia         ARE   \n",
       "2  take a look inside your heart is there any roo...       Asia         ARE   \n",
       "3  vibez oh no another banger baby calm down calm...       Asia         ARE   \n",
       "4  ooh oohooh oohoohooh ooh oohooh just cant beli...       Asia         ARE   \n",
       "\n",
       "   len_words_orig  len_words_trans  \\\n",
       "0             334              334   \n",
       "1             362              362   \n",
       "2             372              372   \n",
       "3             495              495   \n",
       "4             458              456   \n",
       "\n",
       "                                        lyrics_clean  \n",
       "0  good gold dream sell right til build home watc...  \n",
       "1  fan even though salty hate see broad know happ...  \n",
       "2  take look inside heart room room would hold br...  \n",
       "3  another banger baby calm calm girl body put he...  \n",
       "4  believe man want somebody say saw person kiss ...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ DATA \n",
    "song_data = pd.read_csv('../Data/merged_finaltop100_revised.csv') \n",
    "# REMOVE ROWS WITH NULL VALUES \n",
    "song_data = song_data.dropna()\n",
    "song_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca6af367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE KEY TO CATEGORICAL VARIABLE \n",
    "song_data['key'] = song_data.key.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef996c",
   "metadata": {},
   "source": [
    "## I. Variance Threshold <a class=\"anchor\" id=\"var\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac7d0e",
   "metadata": {},
   "source": [
    "Variance threshold is a widely used technique for feature selection, which involves eliminating features with low variance. Such features are characterized by having nearly constant values or showing minimal variation across the data points. By utilizing the variance of the features, we can identify and exclude the features that do not meet the specified threshold. Using this method, we assume that features with higher variance provide more useful information. It is important to note that this method does not take into account the relationship between the target and features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84c1de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e77d8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE QUANTITATIVE VARIABLES \n",
    "X = song_data[['valence', 'mode', 'loudness', \n",
    "                'acousticness', 'tempo', 'energy', 'liveness', \n",
    "                'key', 'duration_ms', 'instrumentalness', 'danceability', \n",
    "                'speechiness', 'len_words_orig', 'len_words_trans']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8dbd63fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[4.83936367e-02 2.49423408e-01 5.76396379e+00 5.73799561e-02\n",
      " 8.04333374e+02 2.28960102e-02 1.38679966e-02 1.30240889e+01\n",
      " 2.15771595e+09 8.49994820e-03 1.81675201e-02 9.17713769e-03\n",
      " 2.88829014e+04 2.79634791e+04]\n"
     ]
    }
   ],
   "source": [
    "# SELECT FEATURES USING 0 VARIANCE THRESHOLD \n",
    "var_thresh = VarianceThreshold(threshold =0.0) #set threshold to 0.0 \n",
    "var_thresh.fit(X) \n",
    "print(var_thresh.get_support())\n",
    "print(var_thresh.fit_transform(X).var(axis=0)) #print variances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e9059",
   "metadata": {},
   "source": [
    "This result shows that all features have non-zero variance (`True` = non-zero variance). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c634bc",
   "metadata": {},
   "source": [
    "## II. Filter-based methods <a class=\"anchor\" id=\"filterbased\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772d0a0",
   "metadata": {},
   "source": [
    "Filter-based methods do not use machine learning models to determine if a feature is useful or not unlike wrapper methods. It simply uses simple statistical measures to rank the importance of features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d509e9",
   "metadata": {},
   "source": [
    "### 1. Pearson Correlation <a class=\"anchor\" id=\"pearson\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7f6d1",
   "metadata": {},
   "source": [
    "In feature selection, Pearson's correlation coefficient can be used to identify the features that are highly correlated with the target variable. The absolute value of Pearson’s correlations between the target (streams) and quantitative features (audio&lyrics features) can be used to choose top n features. In this case, top  6 features  are chosen with absolute correlations ranging from approximately 0.03-0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "875beb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = [] #list of correlations \n",
    "feature_names = ['valence', 'mode', 'loudness', \n",
    "                'acousticness', 'tempo', 'energy', 'liveness', \n",
    "                'key', 'duration_ms', 'instrumentalness', 'danceability', \n",
    "                'speechiness', 'len_words_orig', 'len_words_trans'] #list of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3cadb74e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False, True, False, False, False, False, False, False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE CORRELATION BETW EACH FEATURE AND TARGET VARIABLE  \n",
    "corr = [np.corrcoef(song_data[i], song_data['streams'])[0,1] for i in feature_names] \n",
    "corr = np.abs(corr) #absolute value of Peason's correlation \n",
    "corr_feature = X.iloc[:,np.argsort(np.abs(corr))[-6:]].columns.tolist() #chosen top 6 features \n",
    "corr_support = [True if i in corr_feature else False for i in feature_names]\n",
    "print(corr_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70c62b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>abs_pearsoncorr</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>len_words_trans</td>\n",
       "      <td>0.049183</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>0.047060</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>len_words_orig</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>0.036375</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valence</td>\n",
       "      <td>0.029379</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>danceability</td>\n",
       "      <td>0.028526</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>liveness</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mode</td>\n",
       "      <td>0.020552</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tempo</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loudness</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>0.018003</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>duration_ms</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_names  abs_pearsoncorr  support\n",
       "13   len_words_trans         0.049183     True\n",
       "11       speechiness         0.047060     True\n",
       "12    len_words_orig         0.038529     True\n",
       "3       acousticness         0.036375     True\n",
       "0            valence         0.029379     True\n",
       "10      danceability         0.028526     True\n",
       "6           liveness         0.020586    False\n",
       "1               mode         0.020552    False\n",
       "4              tempo         0.019645    False\n",
       "2           loudness         0.019227    False\n",
       "9   instrumentalness         0.018003    False\n",
       "7                key         0.013108    False\n",
       "8        duration_ms         0.008091    False\n",
       "5             energy         0.005559    False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISPLAY RESULTS AS DATAFRAME \n",
    "corr_df = pd.DataFrame({'feature_names': feature_names, \n",
    "                        'abs_pearsoncorr': corr, 'support':corr_support })\n",
    "corr_df.sort_values('abs_pearsoncorr', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3815095",
   "metadata": {},
   "source": [
    "Generally, it appears that audio and lyrics features are weakly correlated with the number of streams.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a533d",
   "metadata": {},
   "source": [
    "### 2. Chi-square Test  <a class=\"anchor\" id=\"chi\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e02d8f",
   "metadata": {},
   "source": [
    "We can also conduct a test of significance called the *Chi-Square Test* to determine whether the association between the target and each of the quantitative features is statistically significant. After calculating the chi-square metric between the target (streams) and quantitative features (audio & lyrics features), we can choose the feature with the largest chi-squared values. The following explains what small and high chi-square values mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86410ce4",
   "metadata": {},
   "source": [
    "- Observed count is close to expected count when 2 features are independent $\\rightarrow$ smaller chi-square value \n",
    "- Observed count is not close to expected count when 2 features are dependent $\\rightarrow$ higher chi-square value \n",
    "\n",
    "Higher Chi-Square values mean a feature is more dependent on the target and it can be selected for model training. For this test, we use the following hypothesis. \n",
    "\n",
    "- Null hypothesis: $H_0$: target and a feature are independent (i.e.  no significant association) \n",
    "\n",
    "- Alternative hypothesis: $H_1$: target and a feature are not independent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e78aa64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9b1522e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET VARIABLES \n",
    "X = song_data[feature_names] #independent variables \n",
    "y = song_data['streams'] #target variable\n",
    "X_norm = MinMaxScaler().fit_transform(X) #scale features (models can be sensitive to scale of input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c50deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  chi-square_values  p_values\n",
      "9   instrumentalness        3368.369840       1.0\n",
      "1               mode        3207.603840       1.0\n",
      "3       acousticness        1540.538880       1.0\n",
      "7                key        1520.387532       1.0\n",
      "11       speechiness         902.343689       1.0\n",
      "0            valence         717.389487       1.0\n",
      "6           liveness         662.960253       1.0\n",
      "4              tempo         493.924591       1.0\n",
      "10      danceability         333.264595       1.0\n",
      "5             energy         261.738070       1.0\n",
      "8        duration_ms         191.133601       1.0\n",
      "12    len_words_orig         175.036027       1.0\n",
      "13   len_words_trans         157.826374       1.0\n",
      "2           loudness         125.937553       1.0\n"
     ]
    }
   ],
   "source": [
    "# GET CHI-SQuare VAUES FOR ALL FEATURES \n",
    "chi_scores = chi2(X_norm,y) #compute chi-sq values \n",
    "scores_df = pd.DataFrame({'feature_names': feature_names, \n",
    "                          'chi-square_values': chi_scores[0], \n",
    "                          'p_values': chi_scores[1]})\n",
    "print(scores_df.sort_values('chi-square_values', ascending= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda15b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 selected features: ['valence', 'mode', 'acousticness', 'key', 'instrumentalness', 'speechiness']\n"
     ]
    }
   ],
   "source": [
    "# GET TOP 5 FEATURES \n",
    "chi_selector = SelectKBest(chi2, k=6) #get top 6 features \n",
    "chi_selector.fit(X_norm, y)\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "print(f\"{len(chi_feature)} selected features: {chi_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0200855",
   "metadata": {},
   "source": [
    "Based on the `p-values` obtained above, which equals 1.0 for all features, we can see that all the features do not have a statistically significant association with the target variable (streams), which supports the weak correlations obtained in the previous section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b31d4e",
   "metadata": {},
   "source": [
    "## Information criterion <a class=\"anchor\" id=\"infocri\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68df03f",
   "metadata": {},
   "source": [
    "Information criteria are commonly used in feature selection to evaluate the information gain of each feature with respect to the target variable. Information criteria are based on the concept of entropy, which is a measure of the uncertainty in a random variable. AIC and BIC are two statistical  measures that are often used in model selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d68a6e",
   "metadata": {},
   "source": [
    "### AIC  <a class=\"anchor\" id=\"aic\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb97988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "025e29b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>key</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>len_words_orig</th>\n",
       "      <th>len_words_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.648231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.754958</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.329883</td>\n",
       "      <td>0.672251</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250501</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.644617</td>\n",
       "      <td>0.051979</td>\n",
       "      <td>0.107597</td>\n",
       "      <td>0.108410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.406654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.052994</td>\n",
       "      <td>0.164828</td>\n",
       "      <td>0.728436</td>\n",
       "      <td>0.151985</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.167554</td>\n",
       "      <td>0.150470</td>\n",
       "      <td>0.562905</td>\n",
       "      <td>0.018956</td>\n",
       "      <td>0.116726</td>\n",
       "      <td>0.117608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.871795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572892</td>\n",
       "      <td>0.256352</td>\n",
       "      <td>0.414990</td>\n",
       "      <td>0.805431</td>\n",
       "      <td>0.244322</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.126652</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.630350</td>\n",
       "      <td>0.031950</td>\n",
       "      <td>0.119987</td>\n",
       "      <td>0.120894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.813520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714133</td>\n",
       "      <td>0.388602</td>\n",
       "      <td>0.267317</td>\n",
       "      <td>0.802310</td>\n",
       "      <td>0.102101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.319813</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.017763</td>\n",
       "      <td>0.160091</td>\n",
       "      <td>0.161301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677108</td>\n",
       "      <td>0.424207</td>\n",
       "      <td>0.215847</td>\n",
       "      <td>0.608782</td>\n",
       "      <td>0.068351</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654994</td>\n",
       "      <td>0.030043</td>\n",
       "      <td>0.148027</td>\n",
       "      <td>0.148489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>0.762662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732994</td>\n",
       "      <td>0.646996</td>\n",
       "      <td>0.795130</td>\n",
       "      <td>0.587972</td>\n",
       "      <td>0.093611</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.278226</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.670558</td>\n",
       "      <td>0.258464</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.192838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>0.776436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588462</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>0.454947</td>\n",
       "      <td>0.458953</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.047330</td>\n",
       "      <td>0.160743</td>\n",
       "      <td>0.161958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>0.422547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460936</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.295818</td>\n",
       "      <td>0.436063</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.634991</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.810636</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.082165</td>\n",
       "      <td>0.134691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>0.296461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312882</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.301495</td>\n",
       "      <td>0.451670</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.696106</td>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.767834</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.132377</td>\n",
       "      <td>0.151774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>0.595253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372382</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.698262</td>\n",
       "      <td>0.240076</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.568898</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.810636</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>0.133681</td>\n",
       "      <td>0.169185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6809 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence  mode  loudness  acousticness     tempo    energy  liveness  \\\n",
       "0     0.648231   1.0  0.754958      0.064286  0.329883  0.672251  0.015283   \n",
       "1     0.406654   1.0  0.689064      0.052994  0.164828  0.728436  0.151985   \n",
       "2     0.871795   1.0  0.572892      0.256352  0.414990  0.805431  0.244322   \n",
       "3     0.813520   1.0  0.714133      0.388602  0.267317  0.802310  0.102101   \n",
       "4     0.146006   0.0  0.677108      0.424207  0.215847  0.608782  0.068351   \n",
       "...        ...   ...       ...           ...       ...       ...       ...   \n",
       "6804  0.762662   1.0  0.732994      0.646996  0.795130  0.587972  0.093611   \n",
       "6805  0.776436   1.0  0.588462      0.026849  0.454947  0.458953  0.072914   \n",
       "6806  0.422547   0.0  0.460936      0.014336  0.295818  0.436063  0.006686   \n",
       "6807  0.296461   0.0  0.312882      0.016880  0.301495  0.451670  0.076098   \n",
       "6808  0.595253   0.0  0.372382      0.011895  0.295824  0.698262  0.240076   \n",
       "\n",
       "           key  duration_ms  instrumentalness  danceability  speechiness  \\\n",
       "0     0.000000     0.250501          0.000005      0.644617     0.051979   \n",
       "1     0.727273     0.167554          0.150470      0.562905     0.018956   \n",
       "2     0.454545     0.126652          0.000134      0.630350     0.031950   \n",
       "3     1.000000     0.319813          0.000699      0.766537     0.017763   \n",
       "4     0.090909     0.288071          0.000000      0.654994     0.030043   \n",
       "...        ...          ...               ...           ...          ...   \n",
       "6804  0.727273     0.278226          0.000005      0.670558     0.258464   \n",
       "6805  0.000000     0.252187          0.000000      0.817121     0.047330   \n",
       "6806  0.727273     0.634991          0.000860      0.810636     0.047210   \n",
       "6807  0.090909     0.696106          0.142111      0.767834     0.032308   \n",
       "6808  0.909091     0.568898          0.001766      0.810636     0.025632   \n",
       "\n",
       "      len_words_orig  len_words_trans  \n",
       "0           0.107597         0.108410  \n",
       "1           0.116726         0.117608  \n",
       "2           0.119987         0.120894  \n",
       "3           0.160091         0.161301  \n",
       "4           0.148027         0.148489  \n",
       "...              ...              ...  \n",
       "6804        0.191392         0.192838  \n",
       "6805        0.160743         0.161958  \n",
       "6806        0.082165         0.134691  \n",
       "6807        0.132377         0.151774  \n",
       "6808        0.133681         0.169185  \n",
       "\n",
       "[6809 rows x 14 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT INDEPENDENT FEATURES TO DATAFRAME \n",
    "xnorm_df = pd.DataFrame(X_norm, columns= X.columns)\n",
    "xnorm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cdb3a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE ALL POSSIBLE SUBSETS OF PREDICTORS \n",
    "subsets = []\n",
    "for k in range(1, X.shape[1] + 1):\n",
    "    subsets.extend(itertools.combinations(range(X.shape[1]), k))\n",
    "\n",
    "# INTIALIZE VARIABLES FOR STORING RESULTS \n",
    "best_model = None\n",
    "best_aic = np.inf\n",
    "best_bic = np.inf\n",
    "best_r2 = -np.inf\n",
    "best_adjr2 = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec057118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP THROUGH ALL SUBSETS AND FIT LINEA REGRESSION MODELS \n",
    "for subset in subsets:\n",
    "    model = sm.OLS(y, sm.add_constant(X_norm[:, list(subset)])).fit()\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    r2 = model.rsquared\n",
    "    adjr2 = model.rsquared_adj\n",
    "    #Check if current model is the best so far\n",
    "    if aic < best_aic: #lower aic = best model \n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_bic = bic\n",
    "        best_r2 = r2\n",
    "        best_adjr2 = adjr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a450b298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>AdjR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']</th>\n",
       "      <td>207483.680486</td>\n",
       "      <td>207545.114491</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.007024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            AIC  \\\n",
       "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']  207483.680486   \n",
       "\n",
       "                                                            BIC        R2  \\\n",
       "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']  207545.114491  0.008191   \n",
       "\n",
       "                                                     AdjR2  \n",
       "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']  0.007024  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST FEATURES USING AIC \n",
    "variables = list(best_model.params.index)\n",
    "variables.remove('const')\n",
    "results = pd.DataFrame({'AIC': [best_aic], 'BIC': [best_bic],  'R2': [best_r2], 'AdjR2': [best_adjr2]}, \n",
    "                       index=[str(variables)])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e923832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  support\n",
      "0            valence     True\n",
      "1               mode     True\n",
      "2           loudness     True\n",
      "3       acousticness     True\n",
      "4              tempo     True\n",
      "5             energy     True\n",
      "6           liveness     True\n",
      "7                key     True\n",
      "8        duration_ms    False\n",
      "9   instrumentalness    False\n",
      "10      danceability    False\n",
      "11       speechiness    False\n",
      "12    len_words_orig    False\n",
      "13   len_words_trans    False\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO DATAFRAME \n",
    "aic_df = pd.DataFrame({'feature_names': X.columns.tolist(),  'support': True})\n",
    "aic_df.loc[8:, 'support'] = False \n",
    "print(aic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093fae9",
   "metadata": {},
   "source": [
    "According to AIC there are 8 best features that maximize the likelihood of the data. However, the extremely low R-squared (0.008191) and adjusted R-squared values suggest that the model explains very little of the variability in the data. In other words, only 0.8191% of the variation in the dependent variable can be explained by the independent variable(s) included in the model. This implies that that the independent variables included in the model do not have a strong relationship with the dependent variable (streams), which supports the previous results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31e518",
   "metadata": {},
   "source": [
    "### BIC <a class=\"anchor\" id=\"bic\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0161166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP THROUGH ALL SUBSETS AND FIT LINEA REGRESSION MODELS \n",
    "for subset in subsets:\n",
    "    model = sm.OLS(y, sm.add_constant(X_norm[:, list(subset)])).fit()\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    r2 = model.rsquared\n",
    "    adjr2 = model.rsquared_adj\n",
    "    #check if current model is the best so far\n",
    "    if bic < best_bic:  #lower bic = best model \n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_bic = bic\n",
    "        best_r2 = r2\n",
    "        best_adjr2 = adjr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3489849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIC</th>\n",
       "      <th>AIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>AdjR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['x1']</th>\n",
       "      <td>207522.844669</td>\n",
       "      <td>207509.192668</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.002272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  BIC            AIC        R2     AdjR2\n",
       "['x1']  207522.844669  207509.192668  0.002419  0.002272"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST FEATURES USING BIC \n",
    "variables = list(best_model.params.index)\n",
    "variables.remove('const')\n",
    "results = pd.DataFrame({'BIC': [best_bic], 'AIC': [best_aic],  'R2': [best_r2], 'AdjR2': [best_adjr2]}, \n",
    "                       index=[str(variables)])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0cbcc410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  support\n",
      "0            valence     True\n",
      "1               mode    False\n",
      "2           loudness    False\n",
      "3       acousticness    False\n",
      "4              tempo    False\n",
      "5             energy    False\n",
      "6           liveness    False\n",
      "7                key    False\n",
      "8        duration_ms    False\n",
      "9   instrumentalness    False\n",
      "10      danceability    False\n",
      "11       speechiness    False\n",
      "12    len_words_orig    False\n",
      "13   len_words_trans    False\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO DATAFRAME \n",
    "bic_df = pd.DataFrame({'feature_names': X.columns.tolist(),  'support': False})\n",
    "bic_df.loc[0, 'support'] = True  \n",
    "print(bic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdc847",
   "metadata": {},
   "source": [
    "Using BIC, there is only 1 best feature identified. However, the R-squared and adjusted R-squared values are much lower compare to AIC. Hence, the independent variable chosen does not have a strong relationship with the dependent variable (streams). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1020ea",
   "metadata": {},
   "source": [
    "## Wrapper-based methods <a class=\"anchor\" id=\"wrapper\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9eed8b",
   "metadata": {},
   "source": [
    "Wrapper-based methods are useful in feature selection because they use a machine learning algorithm to evaluate the performance of each subset of features. They involve training and evaluating a model with different subsets of features, and the selection of features is based on the performance of the model on a validation set. Wrapper methods can provide a more accurate estimate of the performance of each subset of features compared to filter-based methods, which use simple statistical measures to rank the importance of features. By using a machine learning algorithm, wrapper methods can capture complex interactions between features and identify non-linear relationships between features and the outcome variable.\n",
    "\n",
    "Additionally, wrapper methods also allow for the selection of subsets of features that are specific to the machine learning algorithm being used, rather than relying on a single criterion, such as variance or correlation, as in filter-based methods. This can lead to more efficient and accurate models that are tailored to the specific problem being solved. However, wrapper-based methods can be computationally expensive and time-consuming, as they require the training and evaluation of a model for each subset of features. In addition, wrapper methods can be prone to overfitting, as they can select features that are specific to the training data and may not generalize well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d43bda",
   "metadata": {},
   "source": [
    "### 1. Recursive Feature Elimination <a class=\"anchor\" id=\"recursive\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ec01c",
   "metadata": {},
   "source": [
    "RFE reduces model complexity by removing features one by one until the optimal number of features is left (aka Backward Elimination). We can use RFE to select features by recursively considering smaller and smaller sets of features. RFE can be used with different estimators such as Logistic Regression and Linear Regression. Since the target variable in this case is continuous, RFE is used with Linear regression estimator.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a067f",
   "metadata": {},
   "source": [
    "**RFE - Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a60abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "01decfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM RFE AND SELECT TOP 6 FEATURES \n",
    "estimator = LinearRegression() #define estimator \n",
    "rfe_lr = RFE(estimator, n_features_to_select=6, step=1)\n",
    "rfe_lr.fit(X_norm, y)\n",
    "rfe_lr_support = rfe_lr.get_support()\n",
    "rfe_lr_feature = X.loc[:,rfe_lr_support].columns.tolist()\n",
    "#print(f\"Initial features: {X.columns.tolist()}\")\n",
    "#print(f\"Feature Ranking: {rfe_lr.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f22ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  feature_ranking  support\n",
      "0            valence                1     True\n",
      "2           loudness                1     True\n",
      "3       acousticness                1     True\n",
      "11       speechiness                1     True\n",
      "12    len_words_orig                1     True\n",
      "13   len_words_trans                1     True\n",
      "10      danceability                2    False\n",
      "6           liveness                3    False\n",
      "5             energy                4    False\n",
      "9   instrumentalness                5    False\n",
      "8        duration_ms                6    False\n",
      "4              tempo                7    False\n",
      "7                key                8    False\n",
      "1               mode                9    False\n",
      "6 selected features: ['valence', 'loudness', 'acousticness', 'speechiness', 'len_words_orig', 'len_words_trans'] \n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO DATAFRAME \n",
    "df = pd.DataFrame({'feature_names': X.columns.tolist(), \n",
    "                          'feature_ranking': rfe_lr.ranking_, 'support': rfe_lr_support})\n",
    "print(df.sort_values('feature_ranking'))\n",
    "print(f\"{len(rfe_lr_feature)} selected features: {rfe_lr_feature} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c3061ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1046198083685.7289\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE PERFORMANCE \n",
    "X_selected = rfe_lr.transform(X_norm)\n",
    "#split transformed dataset & target variable into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "estimator.fit(X_train, y_train) #fit a regression model on training set \n",
    "y_pred = estimator.predict(X_test) #predict on test set\n",
    "mse = mean_squared_error(y_test, y_pred) #compute mse\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b4d47",
   "metadata": {},
   "source": [
    "**RFECV - DecisionTreeRegressor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3873132",
   "metadata": {},
   "source": [
    "RFECV is a feature selection method that combines the recursive feature elimination (RFE) algorithm with cross-validation. It recursively eliminate less important features based on their coefficients or importance scores, and then evaluate the performance of the resulting model using cross-validation.  The RFE algorithm is used to recursively eliminate features from the dataset until the desired number of features is reached and  RFECV uses cross-validation to estimate the performance of the model with different numbers of features. RFECV is advantageous because of the following reasons: \n",
    "\n",
    "- RFECV avoids overfitting by using cross-validation to estimate the model's performance.\n",
    "- RFECV helps to identify the optimal number of features to use in the model.\n",
    "- RFECV reduces the risk of selecting a suboptimal subset of features by evaluating multiple subsets using cross-validation.\n",
    "- RFECV can handle noisy or correlated features by considering the joint effect of features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8da4732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0493399e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFECV(cv=5, estimator=DecisionTreeRegressor())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFECV</label><div class=\"sk-toggleable__content\"><pre>RFECV(cv=5, estimator=DecisionTreeRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFECV(cv=5, estimator=DecisionTreeRegressor())"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PERFORM RFECV\n",
    "estimator = DecisionTreeRegressor() #use decision tree estimator \n",
    "rfecv_dtr = RFECV(estimator=estimator,step=1, cv=5)\n",
    "rfecv_dtr.fit(X_norm, y)\n",
    "#print(f\"Feature Ranking: {rfecv_dtr.ranking_}\")\n",
    "#print(f\"Initial features: {X.columns.tolist()}\")\n",
    "#print(rfecv_dtr.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa65447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  feature_ranking  support\n",
      "4              tempo                1     True\n",
      "0            valence                2    False\n",
      "8        duration_ms                3    False\n",
      "2           loudness                4    False\n",
      "13   len_words_trans                5    False\n",
      "3       acousticness                6    False\n",
      "6           liveness                7    False\n",
      "12    len_words_orig                8    False\n",
      "11       speechiness                9    False\n",
      "10      danceability               10    False\n",
      "5             energy               11    False\n",
      "9   instrumentalness               12    False\n",
      "7                key               13    False\n",
      "1               mode               14    False\n",
      "Number of features selected with CV: 1\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO DATAFRAME \n",
    "df = pd.DataFrame({'feature_names': X.columns.tolist(), \n",
    "                          'feature_ranking': rfecv_dtr.ranking_, 'support': rfecv_dtr.support_})\n",
    "print(df.sort_values('feature_ranking'))\n",
    "print(f\"Number of features selected with CV: {rfecv_dtr.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f3deb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1683888684985.9526\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE PERFORMANCE\n",
    "X_selected = rfecv_dtr.transform(X_norm)\n",
    "#split transformed dataset & target variable into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "estimator.fit(X_train, y_train) #fit a regression model on training set \n",
    "y_pred = estimator.predict(X_test) #predict on test set\n",
    "mse = mean_squared_error(y_test, y_pred) #compute mse\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e4cde5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  feature_ranking  support\n",
      "4              tempo                1     True\n",
      "3       acousticness                2    False\n",
      "0            valence                3    False\n",
      "6           liveness                3    False\n",
      "8        duration_ms                4    False\n",
      "13   len_words_trans                4    False\n",
      "2           loudness                5    False\n",
      "5             energy                5    False\n",
      "11       speechiness                6    False\n",
      "12    len_words_orig                6    False\n",
      "9   instrumentalness                7    False\n",
      "10      danceability                7    False\n",
      "1               mode                8    False\n",
      "7                key                8    False\n",
      "Number of features selected with CV: 1\n"
     ]
    }
   ],
   "source": [
    "# PERFORM RFECV WITH SPECIFIED SCORING AND DIFFERENT STEP AND CV\n",
    "rfecv_dtr = RFECV(estimator=estimator,scoring=\"neg_mean_squared_error\", step=2, cv=2)\n",
    "rfecv_dtr.fit(X_norm, y)\n",
    "df = pd.DataFrame({'feature_names': X.columns.tolist(), \n",
    "                          'feature_ranking': rfecv_dtr.ranking_, 'support': rfecv_dtr.support_})\n",
    "print(df.sort_values('feature_ranking'))\n",
    "print(f\"Number of features selected with CV: {rfecv_dtr.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "673e4cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1683888684985.9526\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE PERFORMANCE\n",
    "X_selected = rfecv_dtr.transform(X_norm)\n",
    "#split transformed dataset & target variable into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "estimator.fit(X_train, y_train) #fit a regression model on training set \n",
    "y_pred = estimator.predict(X_test) #predict on test set\n",
    "mse = mean_squared_error(y_test, y_pred) #compute mse\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb261de",
   "metadata": {},
   "source": [
    "The computed MSE values for RFE AND RFECV using different estimators are significantly high, which suggests that none of the independent variables are useful for predicting song popularity measure by number of streams. This also supports the previous results obtained using other methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ebebb",
   "metadata": {},
   "source": [
    "### 2. Forward Feature Selection  <a class=\"anchor\" id=\"forward\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cb276",
   "metadata": {},
   "source": [
    "Forward selection is a feature selection method that works by iteratively adding one feature at a time to the model until a stopping criterion is met. The algorithm starts with an empty set of features and evaluates the performance of the model with each additional feature, selecting the feature that improves the performance the most. Forward selection is helpful in feature selection because it can improve the efficiency and effectiveness of the modeling process in several ways:\n",
    "\n",
    "- Faster convergence\n",
    "- Reduce the dimensionality of the dataset by selecting only the most relevant features\n",
    "- Improve the interpretability of the model by selecting a subset of features that are most relevant to the outcome of interest\n",
    "\n",
    "Disadvantages of forward selection: \n",
    "\n",
    "-  Overfits data if the stopping criterion is not carefully chosen\n",
    "-  Ignores important interactions between in independent variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4465f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d18d0081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  support\n",
      "0            valence    False\n",
      "1               mode     True\n",
      "2           loudness    False\n",
      "3       acousticness    False\n",
      "4              tempo     True\n",
      "5             energy    False\n",
      "6           liveness    False\n",
      "7                key     True\n",
      "8        duration_ms    False\n",
      "9   instrumentalness     True\n",
      "10      danceability    False\n",
      "11       speechiness     True\n",
      "12    len_words_orig     True\n",
      "13   len_words_trans     True\n",
      "Optimal subset size using forward feature selection: 7\n"
     ]
    }
   ],
   "source": [
    "# PERFORM FORWARD SELECTION AND AUTO SELECT NUMBER OF FEATURES \n",
    "sfs = SequentialFeatureSelector(LinearRegression(), n_features_to_select='auto', direction='forward')\n",
    "sfs.fit(X_norm, y)\n",
    "sfs_support = sfs.get_support()\n",
    "\n",
    "# CONVERT TO DATAFRAME \n",
    "df = pd.DataFrame({'feature_names': X.columns.tolist(), 'support': sfs_support})\n",
    "print(df)\n",
    "sfs_feature = X.loc[:,sfs_support].columns.tolist()\n",
    "print(f\"Optimal subset size using forward feature selection: {len(sfs_feature)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2451d3",
   "metadata": {},
   "source": [
    "### 3. Backward Elimination  <a class=\"anchor\" id=\"backward\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e3a31",
   "metadata": {},
   "source": [
    "Backward elimination works similar to RFE with some differences: \n",
    "\n",
    "- RFE: Fit model with all features $\\rightarrow$ Compute variable coefficients and their importance $\\rightarrow$ Eliminate low ranking variable in each iteration\n",
    "\n",
    "- BE: Fit model with all features $\\rightarrow$ Choose features with p-values < chosen significance level $\\rightarrow$ Repeat the process until the removal of any variable affect the accuracy of the model (Stop if there is no more effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "064ee721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  support\n",
      "0            valence    False\n",
      "1               mode     True\n",
      "2           loudness     True\n",
      "3       acousticness    False\n",
      "4              tempo     True\n",
      "5             energy     True\n",
      "6           liveness    False\n",
      "7                key     True\n",
      "8        duration_ms    False\n",
      "9   instrumentalness    False\n",
      "10      danceability    False\n",
      "11       speechiness     True\n",
      "12    len_words_orig    False\n",
      "13   len_words_trans     True\n",
      "Optimal subset size using forward feature selection: 7\n"
     ]
    }
   ],
   "source": [
    "# PERFORM BACKWARD SELECTION AND AUTO SELECT NUMBER OF FEATURES \n",
    "sfs2 = SequentialFeatureSelector(LinearRegression(), n_features_to_select='auto', direction='backward')\n",
    "sfs2.fit(X_norm, y)\n",
    "sfs2_support = sfs2.get_support()\n",
    "\n",
    "# CONVERT TO DATAFRAME \n",
    "df = pd.DataFrame({'feature_names': X.columns.tolist(), 'support': sfs2_support})\n",
    "print(df)\n",
    "sfs2_feature = X.loc[:,sfs2_support].columns.tolist()\n",
    "print(f\"Optimal subset size using forward feature selection: {len(sfs2_feature)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417fe6b",
   "metadata": {},
   "source": [
    "Forward and backward elimination both selected the top 7 features, but the sets of chosen features are not identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a7483",
   "metadata": {},
   "source": [
    "## Embedded methods  <a class=\"anchor\" id=\"embedded\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5708b9",
   "metadata": {},
   "source": [
    "Embedded methods are highly useful in feature selection because they incorporate feature selection directly into the model building process. In embedded methods, feature selection is performed simultaneously with model fitting, rather than as a separate step. Embedded methods work by adding a penalty term to the objective function of the model, which encourages the model to select only the most relevant features. This penalty term is usually controlled by a hyperparameter that needs to be tuned to achieve optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bceed68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eddbaca",
   "metadata": {},
   "source": [
    "### 1. Tree-based - SelectFromModel <a class=\"anchor\" id=\"tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1ad3e",
   "metadata": {},
   "source": [
    "RandomForestRegressor is an ensemble learning method that combines multiple decision trees to make predictions for a continuous dependent variable (streams). Higher `n_estimators`  improves performance of random forest by reducing overfitting and increasing prediction stability but increases computational cost. One of its main advantages is its ability to handle complex, high-dimensional data with many predictor variables. It can also handle both linear and nonlinear relationships between the predictors and the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e0645a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature_names  support\n",
      "0            valence     True\n",
      "1               mode    False\n",
      "2           loudness    False\n",
      "3       acousticness    False\n",
      "4              tempo     True\n",
      "5             energy     True\n",
      "6           liveness     True\n",
      "7                key    False\n",
      "8        duration_ms     True\n",
      "9   instrumentalness    False\n",
      "10      danceability    False\n",
      "11       speechiness    False\n",
      "12    len_words_orig    False\n",
      "13   len_words_trans     True\n",
      "6 selected features: ['valence', 'tempo', 'energy', 'liveness', 'duration_ms', 'len_words_trans'] \n"
     ]
    }
   ],
   "source": [
    "#set hyperparam n_estimators=50 \n",
    "embedded_rf = SelectFromModel(RandomForestRegressor(n_estimators=50), max_features=6)\n",
    "embedded_rf.fit(X_norm, y)\n",
    "embedded_rf_support = embedded_rf.get_support()\n",
    "embedded_rf_feature = X.loc[:,embedded_rf_support].columns.tolist()\n",
    "\n",
    "# CONVERT TO DATAFRAME \n",
    "df = pd.DataFrame({'feature_names': X.columns.tolist(), 'support': embedded_rf_support})\n",
    "print(df)\n",
    "print(f\"{len(embedded_rf_feature)} selected features: {embedded_rf_feature} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca2d3",
   "metadata": {},
   "source": [
    "### 2. Lasso Regularization <a class=\"anchor\" id=\"lasso\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcc4a6",
   "metadata": {},
   "source": [
    "Lasso regularization is a method used in linear regression to prevent overfitting and improve the generalization performance of the model. It is a form of regularization that adds a penalty term to the objective function of the linear regression problem. The penalty term in Lasso regression is the sum of the absolute values of the coefficients (i.e., the L1 norm of the coefficients) multiplied by a regularization parameter (lambda or alpha). The addition of this penalty term shrinks the coefficients towards zero, leading to a sparse set of non-zero coefficients that correspond to the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "933be73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valence</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mode</td>\n",
       "      <td>8.774039e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loudness</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tempo</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>energy</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>liveness</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>duration_ms</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>danceability</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>len_words_orig</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>len_words_trans</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_names  coefficients\n",
       "0            valence  0.000000e+00\n",
       "1               mode  8.774039e-12\n",
       "2           loudness  0.000000e+00\n",
       "3       acousticness  0.000000e+00\n",
       "4              tempo  0.000000e+00\n",
       "5             energy -0.000000e+00\n",
       "6           liveness  0.000000e+00\n",
       "7                key  0.000000e+00\n",
       "8        duration_ms -0.000000e+00\n",
       "9   instrumentalness -0.000000e+00\n",
       "10      danceability -0.000000e+00\n",
       "11       speechiness -0.000000e+00\n",
       "12    len_words_orig -0.000000e+00\n",
       "13   len_words_trans -0.000000e+00"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT FEATURES USING LASSO REG \n",
    "reg = LassoCV()\n",
    "reg.fit(X_norm, y)\n",
    "df = pd.DataFrame({'feature_names': feature_names, 'coefficients': reg.coef_})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d20121",
   "metadata": {},
   "source": [
    "If a feature is irrelevant, lasso penalizes its coefficient and makes it 0. The result above shows that most of the features are not relevant based on their coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d7d43",
   "metadata": {},
   "source": [
    "## Combined results  <a class=\"anchor\" id=\"comb\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ec400",
   "metadata": {},
   "source": [
    "In order to easily compare the results obtained using different methods that take into account the relationship between each feature to the target, they are consolidated into a dataframe presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "81daac87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Chi-2</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>RFE_LinearRegression</th>\n",
       "      <th>RFECV_DecisionTreeRegressor</th>\n",
       "      <th>FFS_LinearRegression</th>\n",
       "      <th>BE_LinearRegression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valence</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tempo</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>len_words_trans</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mode</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loudness</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>energy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>len_words_orig</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>liveness</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>duration_ms</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>danceability</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Pearson  Chi-2    AIC    BIC  RFE_LinearRegression  \\\n",
       "0            valence     True   True   True   True                  True   \n",
       "4              tempo    False  False   True  False                 False   \n",
       "11       speechiness     True   True  False  False                  True   \n",
       "13   len_words_trans     True  False  False  False                  True   \n",
       "1               mode    False   True   True  False                 False   \n",
       "3       acousticness     True   True   True  False                  True   \n",
       "7                key    False   True   True  False                 False   \n",
       "2           loudness    False  False   True  False                  True   \n",
       "5             energy    False  False   True  False                 False   \n",
       "12    len_words_orig     True  False  False  False                  True   \n",
       "6           liveness    False  False   True  False                 False   \n",
       "9   instrumentalness    False   True  False  False                 False   \n",
       "8        duration_ms    False  False  False  False                 False   \n",
       "10      danceability     True  False  False  False                 False   \n",
       "\n",
       "    RFECV_DecisionTreeRegressor  FFS_LinearRegression  BE_LinearRegression  \\\n",
       "0                         False                 False                False   \n",
       "4                          True                  True                 True   \n",
       "11                        False                  True                 True   \n",
       "13                        False                  True                 True   \n",
       "1                         False                  True                 True   \n",
       "3                         False                 False                False   \n",
       "7                         False                  True                 True   \n",
       "2                         False                 False                 True   \n",
       "5                         False                 False                 True   \n",
       "12                        False                  True                False   \n",
       "6                         False                 False                False   \n",
       "9                         False                  True                False   \n",
       "8                         False                 False                False   \n",
       "10                        False                 False                False   \n",
       "\n",
       "    Random Forest  Total  \n",
       "0            True      6  \n",
       "4            True      5  \n",
       "11          False      5  \n",
       "13           True      5  \n",
       "1           False      4  \n",
       "3           False      4  \n",
       "7           False      4  \n",
       "2           False      3  \n",
       "5            True      3  \n",
       "12          False      3  \n",
       "6            True      2  \n",
       "9           False      2  \n",
       "8            True      1  \n",
       "10          False      1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureselection_df = pd.DataFrame({'Feature':feature_names,\n",
    "                                    'Pearson':corr_support, \n",
    "                                    'Chi-2':chi_support, \n",
    "                                    'AIC': aic_df['support'], \n",
    "                                    'BIC': bic_df['support'], \n",
    "                                    'RFE_LinearRegression':rfe_lr_support , \n",
    "                                    'RFECV_DecisionTreeRegressor': rfecv_dtr.support_ , \n",
    "                                    'FFS_LinearRegression':sfs_support, \n",
    "                                    'BE_LinearRegression':sfs2_support,\n",
    "                                    'Random Forest':embedded_rf_support})\n",
    "featureselection_df['Total'] = np.sum(featureselection_df.iloc[:, 1:], axis=1) #sum Trues \n",
    "featureselection_df.sort_values('Total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9610eb",
   "metadata": {},
   "source": [
    "Total = number of `True`s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef20d54",
   "metadata": {},
   "source": [
    "# Predictive Analysis <a class=\"anchor\" id=\"reg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "deb16a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES \n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "80b910f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT INTO TRAINING AND TEST SETS \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1662a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(yhat,y):\n",
    "    \"\"\"sqr error loss\"\"\"\n",
    "    return (yhat - y)**2\n",
    "\n",
    "def fit(X,Y):\n",
    "    \"\"\"fit the OLS from training w/ intercept\"\"\"\n",
    "    lin1 = LinearRegression(fit_intercept=True) # OLS from sklearn\n",
    "    lin1.fit(X,Y) # fit OLS\n",
    "    return np.append(lin1.intercept_,lin1.coef_) # return betahat\n",
    "\n",
    "def predict(x, betahat):\n",
    "    \"\"\"predict for point x\"\"\"\n",
    "    return betahat[0] + x @ betahat[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae19e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE AVERAGE TRAINING AND TEST LOSS \n",
    "n,p = X_norm.shape #get dimensions \n",
    "\n",
    "# COMPUTE LOSSES ON TEST SET \n",
    "betahat = fit(X_train,y_train)\n",
    "Y_hat_te = [predict(x,betahat) for x in X_test]\n",
    "test_losses = [loss(yhat,y) for yhat,y in zip(Y_hat_te,y_test)]\n",
    "\n",
    "# COMPUTE LOSSES ON TRAIN SET \n",
    "Y_hat_tr = [predict(x,betahat) for x in X_train]\n",
    "train_losses = [loss(yhat,y) for yhat,y in zip(Y_hat_tr,y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d3f02cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss: 985083046760.4008\n",
      "test avg loss: 1034618292635.4753\n",
      "n, p : 6809 14\n"
     ]
    }
   ],
   "source": [
    "print(\"train avg loss: {}\\ntest avg loss: {}\".format(np.mean(train_losses), np.mean(test_losses)))\n",
    "print(\"n, p :\",n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e75c4c",
   "metadata": {},
   "source": [
    "Generally, we want the training loss to be smaller than the test loss. The reason for this is that the purpose of training a machine learning model is to optimize it for generalization to new, unseen data. If the training loss is larger than the test loss, it suggests that the model is overfitting to the training data and is not able to generalize well to new data. Ideally, we want the training loss to be small enough that the model can fit the training data well, but not so small that it overfits, causing the test loss to increase. In this case, the train loss is smaller than the test loss so the split is sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9537ec",
   "metadata": {},
   "source": [
    "**Scores of each features using linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cda9dde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence: 4.866863426784755 \n",
      "mode: 4.781261625930871 \n",
      "loudness: 1.9683197099587608 \n",
      "acousticness: 4.793979095391341 \n",
      "tempo: 2.821715977917632 \n",
      "energy: 0.09602678653190241 \n",
      "liveness: 2.333521250752356 \n",
      "key: 0.5454139312819927 \n",
      "duration_ms: 0.0673084007003831 \n",
      "instrumentalness: 1.6787315102411215 \n",
      "danceability: 2.7773774576764736 \n",
      "speechiness: 9.974707855423258 \n",
      "len_words_orig: 4.840817447008443 \n",
      "len_words_trans: 8.656145139661833 \n"
     ]
    }
   ],
   "source": [
    "# PERFORM SELECTION TO GET SCORES \n",
    "fs = SelectKBest(score_func=f_regression, k='all')\n",
    "fs.fit(X_train, y_train)\n",
    "# transform train input data\n",
    "X_train_fs = fs.transform(X_train)\n",
    "# transform test input data\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "# PRINT SCORES FOR EACH FEATURE \n",
    "for i in range(len(fs.scores_)):\n",
    "    print(f\"{feature_names[i]}: { fs.scores_[i]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c6f31",
   "metadata": {},
   "source": [
    "**Evaluate a model that uses all input features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "72e9a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 539245.869\n",
      "MSE: 1034618292635.474\n"
     ]
    }
   ],
   "source": [
    "# FIT LINEAR REGRESSION MODEL \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# EVALUATE MODEL \n",
    "predicted_y = model.predict(X_test) #get predicted values \n",
    "mae = mean_absolute_error(y_test, predicted_y) #mean absolute error \n",
    "mse = ((predicted_y - y_test)**2).mean() #or use sklearn mean_squared_error func\n",
    "print('MAE: %.3f' % mae)\n",
    "print('MSE: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "36c2f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                streams   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     3.033\n",
      "Date:                Thu, 09 Mar 2023   Prob (F-statistic):           0.000110\n",
      "Time:                        16:18:22   Log-Likelihood:                -72572.\n",
      "No. Observations:                4766   AIC:                         1.452e+05\n",
      "Df Residuals:                    4751   BIC:                         1.453e+05\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       2.534e+05    1.4e+05      1.805      0.071   -2.18e+04    5.29e+05\n",
      "x1          1.697e+05   7.32e+04      2.318      0.021    2.62e+04    3.13e+05\n",
      "x2          5.004e+04   2.94e+04      1.703      0.089   -7562.742    1.08e+05\n",
      "x3          2.667e+05   1.85e+05      1.441      0.150   -9.61e+04     6.3e+05\n",
      "x4          1.277e+05   7.01e+04      1.822      0.068   -9677.372    2.65e+05\n",
      "x5          1.112e+05   9.37e+04      1.186      0.236   -7.26e+04    2.95e+05\n",
      "x6         -1.162e+05   1.43e+05     -0.815      0.415   -3.96e+05    1.63e+05\n",
      "x7          1.771e+05   1.17e+05      1.511      0.131   -5.26e+04    4.07e+05\n",
      "x8          3.471e+04   4.45e+04      0.780      0.436   -5.26e+04    1.22e+05\n",
      "x9          1.378e+05   1.99e+05      0.692      0.489   -2.53e+05    5.28e+05\n",
      "x10        -1.472e+05   1.59e+05     -0.923      0.356    -4.6e+05    1.65e+05\n",
      "x11        -7.938e+04      1e+05     -0.792      0.428   -2.76e+05    1.17e+05\n",
      "x12         -2.77e+05   1.41e+05     -1.965      0.049   -5.53e+05    -620.112\n",
      "x13         1.538e+06   7.84e+05      1.963      0.050    2250.959    3.07e+06\n",
      "x14        -2.018e+06    8.2e+05     -2.461      0.014   -3.63e+06    -4.1e+05\n",
      "==============================================================================\n",
      "Omnibus:                     5349.165   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           553712.657\n",
      "Skew:                           5.739   Prob(JB):                         0.00\n",
      "Kurtosis:                      54.542   Cond. No.                         142.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE: 2997150372521.643\n"
     ]
    }
   ],
   "source": [
    "# OBTAIN SUMMARY USING OLS() \n",
    "x = sm.add_constant(X_train) #design matrix (allow computation of intercept)\n",
    "model = sm.OLS(y_train, x).fit()\n",
    "print(model.summary())\n",
    "print('MSE:', model.mse_model) # print MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b3a7c",
   "metadata": {},
   "source": [
    "**Evaluate a model that includes top 5 input features in the combined results table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "81a8b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = song_data[['valence',  'tempo', 'speechiness', 'len_words_trans', 'mode', 'acousticness', 'key']] #inputs \n",
    "y = song_data['streams']\n",
    "X_norm = MinMaxScaler().fit_transform(X) #scale features (ML can be sensitive to scale of input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "81f482f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fc2fffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 539545.956\n",
      "MSE: 1037037766985.242\n"
     ]
    }
   ],
   "source": [
    "# FIT MODEL \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# EVALUATE MODEL \n",
    "predicted_y = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, predicted_y)\n",
    "mse = ((predicted_y - y_test)**2).mean() #or use sklearn mean_squared_error func\n",
    "print('MAE: %.3f' % mae)\n",
    "print('MSE: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "787b2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                streams   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     4.412\n",
      "Date:                Thu, 09 Mar 2023   Prob (F-statistic):           6.78e-05\n",
      "Time:                        16:21:26   Log-Likelihood:                -72577.\n",
      "No. Observations:                4766   AIC:                         1.452e+05\n",
      "Df Residuals:                    4758   BIC:                         1.452e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3.556e+05   6.61e+04      5.377      0.000    2.26e+05    4.85e+05\n",
      "x1          1.521e+05   6.24e+04      2.437      0.015    2.98e+04    2.74e+05\n",
      "x2          1.296e+05   9.09e+04      1.427      0.154   -4.85e+04    3.08e+05\n",
      "x3         -3.285e+05   1.34e+05     -2.446      0.014   -5.92e+05   -6.52e+04\n",
      "x4         -4.753e+05   2.76e+05     -1.721      0.085   -1.02e+06    6.61e+04\n",
      "x5          5.548e+04   2.92e+04      1.900      0.058   -1779.946    1.13e+05\n",
      "x6           1.22e+05   6.02e+04      2.029      0.043    4097.666     2.4e+05\n",
      "x7           3.24e+04   4.44e+04      0.730      0.466   -5.47e+04    1.19e+05\n",
      "==============================================================================\n",
      "Omnibus:                     5352.588   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           552917.268\n",
      "Skew:                           5.747   Prob(JB):                         0.00\n",
      "Kurtosis:                      54.500   Cond. No.                         28.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE: 4363608708764.5713\n"
     ]
    }
   ],
   "source": [
    "# OBTAIN SUMMARY USING OLS() \n",
    "x = sm.add_constant(X_train) #design matrix (allow computation of intercept)\n",
    "model = sm.OLS(y_train, x).fit()\n",
    "print(model.summary())\n",
    "print('MSE:', model.mse_model) # print MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef56df",
   "metadata": {},
   "source": [
    "Based on the results obtained above using different methods, it is evident that audio and lyrics features are not very useful for predicting popularity measured by number of streams. Thus, we can conclude that the chosen fatures are not as effective in explaining stream count on its own. There are some reasons that likely limit the explanatory power of\n",
    "this model. Since all genres are included for measuring\n",
    "popularity, it is likely that, because different genres do not share\n",
    "the same popular attributes, there will be noise in the hit\n",
    "prediction model making for a lower R2 value and lower\n",
    "correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064fc5d1",
   "metadata": {},
   "source": [
    "*References*: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3] *",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "398.477px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
